üöÄ AdTech ETL Pipeline: Automated Weekly Performance Reports
üìù Project Overview:This project implements a robust, event-driven Extract, Transform, Load (ETL) pipeline to automate the generation of Weekly Performance Reports for AdTech Account Managers. It transforms a slow, manual, and error-prone process into a real-time, intelligent reporting system.The core innovation is the integration of Isolation Forest for mathematical anomaly detection and Google Gemini 1.5 Pro for AI-driven, actionable analysis, eliminating the reporting lag that often leads to wasted ad spend.The Pain Point (The "Why")Account Managers typically spend 4‚Äì6 hours per week manually generating reports by downloading CSVs and creating screenshots. This process is highly inefficient and creates a significant reporting delay. When a campaign begins wasting budget, the client might not know for days, resulting in lost revenue and client dissatisfaction.Expected End ResultInput: A raw CSV performance file dropped into a monitored folder.Action: Automated ETL process triggers within seconds.Output: A professionally formatted PDF report emailed to the stakeholder, containing:Week-over-Week performance charts.A list of mathematically detected anomalies.An AI-written paragraph explaining why the anomaly occurred (e.g., correlating a traffic drop with external data like severe weather).
üèóÔ∏è System Architecture & Technical StackThe pipeline is built with a focus on speed, stability, and production readiness.Core ComponentsComponentTechnologyRoleProduction Readiness FeatureIngestionwatchdog (Python)Event-driven process monitoring the input folder for file creation.Guarantees real-time processing the moment data is available.Data EnginePolarsHigh-performance DataFrame library for reading and transformation.Strict Schema Enforcement and Parallel Processing for speed and bug reduction.Anomaly Detectionscikit-learn (IsolationForest)Mathematically identifies statistical outliers in key metrics (Spend, Conversions).Moves beyond hard-coded if/else rules for true mathematical insight.Generative AIGoogle Gemini 1.5 ProCorrelates anomalies with external data (simulated Weather API) and generates narrative analysis.Uses Few-Shot Prompting to enforce a "Senior Data Analyst" persona and includes a Validation Guardrail to prevent hallucinations.Reporting (Load)WeasyPrintConverts a generated HTML/CSS template into a pixel-perfect, shareable PDF.Ensures professional, standardized, and client-facing output.
‚öôÔ∏è Setup and InstallationPrerequisitesPython 3.9+A Gemini API Key for the Generative AI component.Installation StepsClone the Repository:Bashgit clone [Your Repository URL]
cd GT_Hackathon
Create and Activate Virtual Environment:Bashpython -m venv venv
.\venv\Scripts\activate  # Windows (or source venv/bin/activate for macOS/Linux)
Install Python Dependencies:Bashpip install watchdog polars scikit-learn google-genai requests weasyprint
Install WeasyPrint System Dependencies (Windows Only):Download and install the necessary GTK+ dependencies (Pango, Cairo) as described in the WeasyPrint documentation, and ensure the /bin directory is added to your session's PATH.ConfigurationSet your Gemini API Key as an environment variable in your active terminal session:Bashset GEMINI_API_KEY="YOUR_ACTUAL_API_KEY_HERE"
‚ñ∂Ô∏è How to Run the PipelineCreate the Monitored Directory:Bashmkdir input_files
Start the Ingestion Service:Bashpython ingestion_service.py
The script will start monitoring and printing its status.Trigger the Report:Place a valid CSV file (following the schema below) into the ./input_files folder.The pipeline will trigger automatically, run the ETL and AI analysis, and produce a [filename]_Report.pdf in the same directory.CSV SchemaColumn NameData Type (Polars)PurposeDatepl.DateUsed for weekly grouping and WoW calculation.Campaign_IDpl.Int64Identifier.Spendpl.Float64Core metric for WoW and Anomaly Detection.Impressionspl.Int64Core metric for Anomaly Detection.Conversionspl.Int64Core metric for Anomaly Detection.Locationpl.Utf8Used for geographical drill-down in the AI analysis.
